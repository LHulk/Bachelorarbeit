%!TEX root = ../bachelor.tex
\chapter{Fazit und Ausblick}
\label{ch:summary}
In der vorliegenden Arbeit haben wir zwei Verfahren vorgestellt mit denen Kegeloberflächen anhand eines Kalibrierungsmusters entzerrt werden können so, dass die relative Vergleichbarkeit der Larven gewährleistet ist.

Der Vorteil der Rückwärtsentfaltung gegenüber der Vorwärtsentfaltung ist die Abwesenheit von Defekten. Diese lieferte
darüberhinaus auch bei starken Abweichungen der Kamera vom Lot gute Ergebnisse und darüberhinaus bei einer Ausgabeauflösung der Seitenhöhe unter 850 Pixel eine bessere Laufzeit.

Denoch wollen wir an dieser Stelle einen Ausblick auf mögliche Verbesserungenvorschläge für die verwendeten Verfahren geben.

\section{Parallelisierung}
Da der Kalibrierungsprozess nur ein Mal vor der eigentlichen Entzerrung durchgeführt wird, bietet sich eine Parallelisierung hier deshalb nur bedingt an.
Dennoch könnte man hier besonders bei den komplexeren Aufgaben, wie der Liniendetektion und anschließenden Schnittpunktberechnung, sowie der Ellipsendetektion auf parallele Methoden zurückgreifen.
Für eine parallele Implementierung der Hough-Transformation sei auf die Arbeit von Havel \cite{Havel2014} verwiesen.
Bei der Ellipsendetektion mittels RANSAC werden für eine vorher definierte Anzahl an Iterationen, wiederholt Punkte ausgewählt mit denen anschließend eine Ellipse geschätzt wird. Es bietet sich hier an, mehrere Gruppen von Punkten parallel zu verarbeiten.

Von größerer Bedeutung ist eine Laufzeitverbesserung der Entzerrung. Nach der Bestimmung der Abbildungsmatrizen werden nach dem, in Kapitel \ref{ch:implementation}, beschriebenen Schema eine Reihe von Bildern entzerrt. Um die aufgenommenen Bilder nicht zwischenspeichern zu müssen, wäre eine echtzeitfähige Entfaltung wünschenswert. Die Bilder könnten somit direkt entzerrt gespeichert werden.  Um die Laufzeit der Entfaltung zu verbessern könnte man hier beispielsweise parallel mehrere Blöcke von Pixeln gleichzeitig verarbeiten.


\section{Verbesserung der Linien-Detektion}
Die Linien-Detektion basiert auf Hough-Transformationen und funktioniert nur mit relativ homogenen Hintergründen. Darüber hinaus werden durch den aktuellen Ansatz sehr viele Linien detektiert, wobei anschließend die Schnittpunkte zwischen all diesen Kandidaten bestimmt werden müssen. Ein besserer Ansatz wäre, die Gradientenrichtung des Kantenbilds miteinzubeziehen. Dies reduziert die Anzahl falscher Votes und verbessert darüber hinaus die Laufzeit \cite{Gorman1976}.


\section{Verbesserung der Vorwärtsentfaltung}
Das Hauptproblem der Vorwärtsentfaltung sind die Defekte auf dem entfalteten Bild. Man könnte mit Hilfe einer Delaunay-Triangulierung versuchen, die Defekte zu beheben.
Die auf die Mantelfläche abgebildeten Punkte werden bei diesem Verfahren nicht gerundet. Anschließend werden die Punkte trianguliert. Es entstehen Dreiecksnetze, wie beispielhaft in Abbildung \ref{fig:delaunayTriag} zu sehen sind. Zum Zwecke der Veranschaulichung wurde hierbei nur ein Teil der Daten benutzt. Mit Hilfe dieser Dreiecke wird nun das Ergebnisbild abgetastet, das heißt man untersucht für jedes Pixel auf dem entzerrten Bild in welchem Dreieck es sich befindet und bestimmt dann die Farbe des Pixels mittels baryzentrischer  Interpolation aus den drei umgebenden Punkten. Die Delaunay-Triangulierung ist jedoch relativ aufwendig mit einer Laufzeit von $\mathcal{O}(p\log p)$ für $p$ Punkte \cite{Su1997}. Sie richtet sich bei einer konstanten Eingabeauflösung also nach der Gesamtanzahl der Pixel im Kalibrierungskegel. Anschließend muss für jedes Pixel auf dem Ausgabebild eine Interpolation (pro Pixel konstanter Aufwand) durchgeführt werden. Die Laufzeit der Vorwärtsentfaltung wird somit quadratisch mit einer großen additiven Konstante bedingt durch die Triangulierung.

\begin{figure}[!htb]
	\centering
	\begin{subfigure}{.9\textwidth}
		\centering
		\includegraphics[angle=-90, width=.8\textwidth]{images/delaunay1.png}
		\caption{Triangulierung mit $10\%$ der Punkte}
	\end{subfigure}
	\begin{subfigure}{.9\textwidth}
		\centering
		\includegraphics[angle=-90, width=.8\textwidth]{images/delaunay2.png}
		\caption{Triangulierung mit $40\%$ der Punkte}
	\end{subfigure}
	\caption{Delaunay-Triangulierung}
	\label{fig:delaunayTriag}
\end{figure}


\section{Verbesserung der Rückwärtsentfaltung}
Aktuell wird die Projektionsmatrix bei der Rückwärtsentfaltung durch Direct Linear Transformation bestimmt. Dieses Verfahren minimiert jedoch nicht den Reprojektionsfehler. Besser wäre hier deshalb ein iteratives Verfahren, wie der Levenberg–Marquardt-Algorithmus (konkret für Projektionsmatrizen beschrieben in \cite{Hartley2000}).
Im Gegensatz dazu könnte auch ein RANSAC-Ansatz verwendet werden. Statt eine optimale Lösung für alle detektierte Samples zu bestimmen, berechnet man wiederholt für sechs Punkte\footnote{sechs Punkte sind mindestens notwendig um eine Projektionsmatrix bestimmen zu können, da es elf unbekannte gibt (siehe Kapitel \ref{s:calib}).} eine Projektionsmatrix und untersucht dann den Reprojektionsfehler für alle anderen Punkte und wählt schließlich die Projektionsmatrix mit dem größten Consensus Set aus.


\section{Verbesserung der Ellipsendetektion mittels Deformable Templates}
Die Minimierung der konstruierten Energiefunktion wird stark durch irrelevante lokale Minima erschwert. Ein Umformulieren der Energiefunktion könnte hier Abhilfe schaffen.
Darüber hinaus müsste genau untersucht werden, wie die Einflussparameter $\alpha,\beta$ und $\gamma$ eingestellt werden müssen, um zuverlässige Ergebnisse zu liefern.
